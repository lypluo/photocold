# p_TS_1_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_1_fluxnet2015","(degreeC)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
# p_SWC_1_len5_b60<-plot_2groups(df_len5_nonnorm,"SWC_1_fluxnet2015","(%)",do_norm = FALSE,FALSE)
#some modifying in the plot:
# p_temp_min_len5_b60$plot<-p_temp_min_len5_b60$plot+
#   ylab("Minimum Ta (°C)")+
#   ylim(-25,25)
p_temp_day_len5_b60$plot<-p_temp_day_len5_b60$plot+
ylab("Mean Ta (°C)")+
ylim(-25,25)
# p_temp_max_len5_b60$plot<-p_temp_max_len5_b60$plot+
#   ylab("Maximum Ta (°C)")+
#   ylim(-25,25)
p_prec_len5_b60$plot<-p_prec_len5_b60$plot+
ylab("prec (mm)")
p_vpd_day_len5_b60$plot<-p_vpd_day_len5_b60$plot+
ylab("vpd_day (Pa)")
# p_SW_IN_len5_b60$plot<-p_SW_IN_len5_b60$plot+
#   ylab("SW_IN (W m-2)")
# p_TS_1_len5_b60$plot<-p_TS_1_len5_b60$plot+
#   ylab("TS (°C)")
# p_SWC_1_len5_b60$plot<-p_SWC_1_len5_b60$plot+
#   ylab("SWC (°C)")
#--------------
#III.PhenoCam VIs
#-------------
#gcc_90
p_gcc_90_len5_b60<-plot_2groups(df_len5_nonnorm,"gcc_90","",do_norm = FALSE,TRUE)
#rcc_90
p_rcc_90_len5_b60<-plot_2groups(df_len5_nonnorm,"rcc_90","",do_norm = FALSE,FALSE)
#GRVI:
p_GRVI_len5_b60<-plot_2groups(df_len5_nonnorm,"GRVI","",do_norm = FALSE,FALSE)
#--------------
#temporary plots:
#-------------
#plot1
# gg_merge<-plot_grid(p_temp_day_len5_b60$plot,p_temp_min_len5_b60$plot,
#                       labels = "auto",nrow =1,label_size = 12,align = "hv")
# save.path<-"D:/CES/Proposal_prepration/MSCA/plots_prepration/plot/"
# ggsave(paste0(save.path,"Ta.png"),gg_merge,width = 15,height = 10)
#plot2-->simplifying the plot
# p_temp_min_len5_b60<-plot_2groups(df_len5_nonnorm,"temp_min_fluxnet2015","(degreeC)",do_norm = FALSE,do_legend = TRUE)
# p_temp_min_len5_b60$plot<-p_temp_min_len5_b60$plot+
#   ylab("Minimum Ta (°C)")+
#   ylim(-15,15)
# save.path<-"D:/CES/Proposal_prepration/MSCA/plots_prepration/plot/"
# ggsave(paste0(save.path,"Ta_min.png"),p_temp_min_len5_b60$plot,width = 10,height = 10)
#-------------------------------------------------------------------------
#(6) save the plot
#-------------------------------------------------------------------------
save.path<-"D:/plots/photocold_project/Using_sites_in_Fluxnet2015/quantile_plot/"
#merge plots
#--------------
#I.GPP and LUE
#-------------
p_merge_Cflux<-plot_grid(p_gpp_obs_len5_b60$plot,
p_ppfd_len5_b60$plot,
p_fapar_itpl_len5_b60$plot,
p_LUE_len5_b60$plot,
p_gpp_biaes_len5_b60$plot,
labels = "auto",nrow=2,label_size = 18,align = "hv")
ggsave(paste0(save.path,"p_Cflux.png"),p_merge_Cflux,width = 20,height = 15)
#--------------
#II.Environment variables
#-------------
# p_merge_EnviroVars<-plot_grid(
#   p_temp_min_len5_b60$plot,p_temp_day_len5_b60$plot,p_temp_max_len5_b60$plot,
#   p_SW_IN_len5_b60$plot,
#   p_prec_len5_b60$plot,
#   p_vpd_day_len5_b60$plot,
#   p_SWC_1_len5_b60$plot,
#   p_TS_1_len5_b60$plot,
#   labels = "auto",nrow=2,label_size = 18,align = "hv")
p_merge_EnviroVars<-plot_grid(
p_temp_day_len5_b60$plot,
p_prec_len5_b60$plot,
p_vpd_day_len5_b60$plot,
labels = "auto",nrow=2,label_size = 18,align = "hv")
ggsave(paste0(save.path,"p_EnviroVars.png"),p_merge_EnviroVars,width = 28,height = 15)
#--------------
#III.PhenoCam VIs
#-------------
p_merge_VIs<-plot_grid(p_gcc_90_len5_b60$plot,
p_rcc_90_len5_b60$plot,
p_GRVI_len5_b60$plot,
labels = "auto",nrow=2,label_size = 18,align = "hv")
ggsave(paste0(save.path,"p_VIs.png"),p_merge_VIs,width = 15,height = 10)
#--------------
#IV.stats-->difference test
#-------------
# stats_merge_Cflux<-rbind(gpp_obs=p_gpp_obs_len5_b60$stats_q50[1,],
#                          ppdf=p_ppfd_len5_b60$stats_q50[1,],
#                          fapar=p_fapar_itpl_len5_b60$stats_q50[1,],
#                          LUE=p_LUE_len5_b60$stats_q50[1,],
#                          gpp_biases=p_gpp_biaes_len5_b60$stats_q50[1,])
# stats_merge_EnviroVars<-rbind(
#   temp_min=p_temp_min_len5_b60$stats_q50[1,],
#   temp_day=p_temp_day_len5_b60$stats_q50[1,],
#   temp_max=p_temp_max_len5_b60$stats_q50[1,],
#   SW_IN=p_SW_IN_len5_b60$stats_q50[1,],
#   prec=p_prec_len5_b60$stats_q50[1,],
#   vpd=p_vpd_day_len5_b60$stats_q50[1,],
#   SWC_1=p_SWC_1_len5_b60$stats_q50[1,],
#   TS_1=p_TS_1_len5_b60$stats_q50[1,])
# stats_merge_VIs<-rbind(gcc_90=p_gcc_90_len5_b60$stats_q50[1,],
#                        rcc_90=p_rcc_90_len5_b60$stats_q50[1,],
#                        GRVI=p_GRVI_len5_b60$stats_q50[1,])
# #
# stats_merge_Cflux$flag<-rep("Cflux",nrow(stats_merge_Cflux))
# stats_merge_EnviroVars$flag<-rep("EnviroVars",nrow(stats_merge_EnviroVars))
# stats_merge_VIs$flag<-rep("VIs",nrow(stats_merge_VIs))
# stats_all<-rbind(stats_merge_Cflux,stats_merge_EnviroVars,stats_merge_VIs)
#----------------------------------------------------------------------
# Aim:label the sites in the on the global maps
#----------------------------------------------------------------------
#load the datasets
#----------------------------------------------------------------------
library(ggplot2)
library(ggmap)
library(rgdal)
library(rgeos)
library(maptools)
library(dplyr)
library(tidyr)
library(tmap)
library(mapdata)
library(rworldmap)
library(rworldxtra)
library(colorRamps)
library(graphics)
library(jpeg)
#(1)load the map
data(coastsCoarse)
#prepration for map
# newmap <- getMap(resolution = "high")[getMap()$ADMIN!='Antarctica',]
newmap <- getMap(resolution = "high")
#add coordinates of sites
#I.load the EC sites Beni provide to me
library("readxl")
#add coordinates of sites
#I.load the EC sites used from Fluxnet 2015
library("readxl")
sites.path<-"D:/data/photocold_project/sel_sites_info/Using_sites_in_Fluxnet2015/"
load(paste0(sites.path,"df_sites_sel.RDA"))
#at the end, two sites do not used for analysis because of the data avaiablity:
#!!need to also update this information tomorrow
# rm_sites<-c("US-Wi3","RU-Ha1")
# pos_rm<-match(rm_sites,coord_Beni$SiteName)
# coord_Beni<-coord_Beni[-pos_rm,]
coord_sites<-df_sites_sel
#---------------------------------------------
#(2)plotting
#---------------------------------------------
library(RColorBrewer)
library(grDevices)
############
# map theme
############
#can refer:http://www.sthda.com/english/wiki/ggplot2-themes-and-background-colors-the-3-elements
theme_map <-
# theme_dark() +    # theme_minimal()
theme(
#add by YP:
# panel.background = element_rect(fill = "gray60",
#                                 colour = "gray60",
#                                 size = 0.5, linetype = "solid"),
# #add by YP:
# plot.background = element_rect(fill="gray60"),
#
plot.title = element_text(hjust = 0, face="bold", size = 18),
# legend.position = "right", # c(0.07, 0.35), #"left"
# legend.key.size = unit(c(5, 1), "mm"),
legend.title=element_text(size=12),
legend.text=element_text(size=10),
# axis.line = element_blank(),
# axis.text = element_blank(),
# axis.title = element_blank(),
# panel.grid.major = element_line(colour="black",size = 0.5,linetype = "solid"),
panel.grid.minor = element_blank(),
# plot.margin = unit( c(0, 0, 0, 5) , "mm")
)
# define labels
lat.labels <- seq(30, 90, 30)
lat.short  <- seq(30, 90, 10)
lon.labels <- seq(-180, 180, 60)
lon.short  <- seq(-180, 180, 10)
a <- sapply( lat.labels, function(x) if (x>0) {parse(text = paste0(x, "*degree ~ N"))} else if (x==0) {parse(text = paste0(x, "*degree"))} else {parse(text = paste0(-x, "*degree ~ S"))} )
b <- sapply( lon.labels, function(x) if (x>0) {parse(text = paste0(x, "*degree ~ E"))} else if (x==0) {parse(text = paste0(x, "*degree"))} else {parse(text = paste0(-x, "*degree ~ W"))} )
#---------------------------------------------
# 1. Create ggplot object
#---------------------------------------------
lonmin=-180
lonmax=180
latmin=30
latmax=90
#group=group-->results in the wrong map background:ask Beni's advices
#something need to be paid attention-->to make sure the plot looks right
#-->should set latmin=-90; latmax=90
#-->and also leave some place for latitude and longtitude-->set the limits in scale_x/y_continous adding or minus some numbers
gg <- ggplot() +
theme_map+
# background countries
# geom_polygon(data=newmap, aes(long, lat, group=group), color=NA, fill='grey75') +
# Coastline
geom_path(data=coastsCoarse, aes(long, lat, group=group), color='black',size=1.02) +
#
scale_x_continuous(expand = c(0,0), limits = c(-1+lonmin,lonmax+1), breaks = lon.labels, labels = b) +
scale_y_continuous(expand = c(0,0), limits = c(-1+latmin,latmax+1), breaks = lat.labels, labels = a) +
labs( x = "longtitude", y = "latitude")
gg+
# geom_point(data=coord_merge[coord_merge$flag=="Beni",],aes(x=Long.,y=Lat.,col="Beni"),size=2,pch=16)+
# geom_point(data=coord_merge[coord_merge$flag=="Beyond",],aes(x=Long.,y=Lat.,col="Beyond"),size=2,pch=16,)+
geom_point(data=coord_sites,aes(x=Long.,y=Lat.,col="Final"),size=4,pch=1)+
# geom_label_repel(data=coord_merge,aes(x=Long.,y=Lat.,label = SiteName,fill = Clim.),
#                  color = 'black',max.overlaps = 50,label.size = 0.1,arrow = arrow(ends = "first",length = unit(0.05,"inch")),
#                  size = 2.5) +
# scale_color_manual("",values = c("Beni"="red","Beyond"="blue","Final"="green"))+
theme(legend.position = "bottom")
head(coord_sites)
gg+
# geom_point(data=coord_merge[coord_merge$flag=="Beni",],aes(x=Long.,y=Lat.,col="Beni"),size=2,pch=16)+
# geom_point(data=coord_merge[coord_merge$flag=="Beyond",],aes(x=Long.,y=Lat.,col="Beyond"),size=2,pch=16,)+
geom_point(data=coord_sites,aes(x=lon,y=lat,col="Final"),size=4,pch=1)+
# geom_label_repel(data=coord_merge,aes(x=Long.,y=Lat.,label = SiteName,fill = Clim.),
#                  color = 'black',max.overlaps = 50,label.size = 0.1,arrow = arrow(ends = "first",length = unit(0.05,"inch")),
#                  size = 2.5) +
# scale_color_manual("",values = c("Beni"="red","Beyond"="blue","Final"="green"))+
theme(legend.position = "bottom")
#############################################################################
#Aim:compare the variables in "event" and "non-event" site years after aligning the data-->specifically for Temp
#-------------------------------------------------------------------------
#(1)load the data that includes the "is_event" information
#-------------------------------------------------------------------------
#---------------------
#A.load the event_length data
#---------------------
load.path<-"D:/data/photocold_project/event_length/Using_sites_in_Fluxnet2015/"
load(paste0(load.path,"df_events_length.RDA"))
# a function to separate out the site-year that event_length higher than some thresholds(e.g. 30 days)
sep_siteyears<-function(df,sep_var,sep_thrs){
# df<-df_events_all
# sep_var<-"Over_days_length"
# sep_thrs<-30
#
df_sep<-df[df[,sep_var]>sep_thrs & !is.na(df[,sep_var]),]
pos_sep<-as.vector(which(df[,sep_var]>sep_thrs))
#as some site the sep_var==NA, hence using this way to separate the data
pos_left<-setdiff(as.vector(1:length(df[,sep_var])),pos_sep)
df_left<-df[pos_left,]
df_new<-list(df_sep,df_left)
names(df_new)<-c("event_siteyears","noevent_siteyears")
return(df_new)
}
##separate the site-year when the over_days_length > 20 days
df.sep20<-sep_siteyears(df_events_all,"Over_days_length",20)
#---------------------
#B.load the data
#---------------------
load.path<-"D:/data/photocold_project/Merge_Data/Using_sites_in_Fluxnet2015/"
#from new method:
load(paste0(load.path,"ddf_labeled_norm_trs_newmethod_all_overestimation_Fluxnet2015_sites.RDA"))
df_all_sites<-ddf_labeled;rm(ddf_labeled)
df_norm_all<-df_all_sites
#-------------------------------------------------------------------------
#(2)start to align the data according to Beni's functions of "align_events" and "get_consecutive"
#-------------------------------------------------------------------------
#---------------------------------
#source the functions to detect the consecutive events
#---------------------------------
fun.path<-"D:/Github/photocold/R/Step2_identify_events/Functions/functions_from_beni/"
#source get_consecutive.R
source(paste0(fun.path,"get_consecutive.R"))
#source get_consecutive_greenup.R
source(paste0(fun.path,"get_consecutive_greenup.R"))
#source align_event.R -->for event site years
source(paste0(fun.path,"align_events_df.R"))
#source align_nonevent.R -->for non-event site years
source(paste0(fun.path,"align_nonevents_df.R"))
df.data<-df_norm_all
dovars<-c("gpp_obs")
df.sep<-df.sep20
leng_threshold<-5
before=30
after=0
nbins=10
do_norm=TRUE
#-------------------------------------------------------------------------
#A.separating the datasets:"event" and "nonevent" site years
#-------------------------------------------------------------------------
N<-nrow(df.sep$event_siteyears)
df_events.years<-c()    #target
df_nonevents.years<-c() #target
#for is.event years
pos.isevent<-c()
for(i in 1:N){
df.temp<-subset(df.data,sitename==df.sep$event_siteyears$sitename[i] & Year==df.sep$event_siteyears$Year[i])
pos.temp<-c(which(df.data$sitename==df.temp$sitename & df.data$Year==df.temp$Year))
df_events.years<-rbind(df_events.years,df.temp)
pos.isevent<-c(pos.isevent,pos.temp)
}
#for no is.event years
pos.non_isevent<-setdiff(c(1:nrow(df.data)),pos.isevent)
df_nonevents.years<-df.data[pos.non_isevent,] #target
#function format
# align_events <- function( df, leng_threshold, before, after, nbins, do_norm=FALSE )
#at this stage-->bins do not used(now set default value as 10)
#-------------
#set different length_threshold-->5 days(consecutive 5 days overestimation will be an event)
#-------------
#and select the 30 days before the events
df_len_events<-align_events(df_events.years,dovars,leng_threshold = leng_threshold,before = before,after = after,
nbins = nbins,do_norm = do_norm)
print("ok")
df_len_nonevents<-align_nonevents(df_nonevents.years,dovars,leng_threshold = leng_threshold,before = before,after = after,
nbins = nbins,do_norm = do_norm)
sep_siteyears_data<-function(df.data,dovars,df.sep,leng_threshold,before,after,nbins,do_norm){
# df.data<-df_norm_all
# dovars<-c("gpp_obs")
# df.sep<-df.sep20
# leng_threshold<-5
# before=30
# after=0
# nbins=10
# do_norm=TRUE
#-------------------------------------------------------------------------
#A.separating the datasets:"event" and "nonevent" site years
#-------------------------------------------------------------------------
N<-nrow(df.sep$event_siteyears)
df_events.years<-c()    #target
df_nonevents.years<-c() #target
#for is.event years
pos.isevent<-c()
for(i in 1:N){
df.temp<-subset(df.data,sitename==df.sep$event_siteyears$sitename[i] & Year==df.sep$event_siteyears$Year[i])
pos.temp<-c(which(df.data$sitename==df.temp$sitename & df.data$Year==df.temp$Year))
df_events.years<-rbind(df_events.years,df.temp)
pos.isevent<-c(pos.isevent,pos.temp)
}
#for no is.event years
pos.non_isevent<-setdiff(c(1:nrow(df.data)),pos.isevent)
df_nonevents.years<-df.data[pos.non_isevent,] #target
#---------------------------------
#B.start to align different events(for event site years) and green-up(for non-event site years) in each site-year
#---------------------------------
# df<-df_norm_all
# leng_threshold<-20
# before=30
# after=30
# nbins=10
# do_norm=FALSE
#function format
# align_events <- function( df, leng_threshold, before, after, nbins, do_norm=FALSE )
#at this stage-->bins do not used(now set default value as 10)
#-------------
#set different length_threshold-->5 days(consecutive 5 days overestimation will be an event)
#-------------
#and select the 30 days before the events
df_len_events<-align_events(df_events.years,dovars,leng_threshold = leng_threshold,before = before,after = after,
nbins = nbins,do_norm = do_norm)
print("ok")
df_len_nonevents<-align_nonevents(df_nonevents.years,dovars,leng_threshold = leng_threshold,before = before,after = after,
nbins = nbins,do_norm = do_norm)
#---------------------------------
#C.separate the df_event and df_nonevent;
#---------------------------------
df_all<-c()
#for event site years
df_dday<-df_len_events$df_dday
#for non_event site years, take the doy belongs to green-up period:
df_noevent_dday<-df_len_nonevents$df_dday
#
df_all<-list(df_dday=df_dday,df_noevent_dday=df_noevent_dday)
return(df_all)
}
#!!important step:leng_threshold=5-->merge the events(consecutive days are over 5 days)
#do_vars-->the variables that are going to be processed:
names(df_norm_all)
do_vars<-c("gpp_obs","fapar_itpl","fapar_spl",paste0(c("ppfd","temp_day","temp_min","temp_max",
"vpd_day","prec","patm","SW_IN","ws",paste0("TS_",1:9),paste0("SWC_",1:5)),"_fluxnet2015"),
"gcc_90","rcc_90")
#set the before events days from 30 days to 60 days
df_len5_nonnorm<-sep_siteyears_data(df_norm_all,do_vars,df.sep20,5,60,0,10,FALSE)
#-------------------------------------------------------------------------
#(3)calculating some important variables like LUE...
#-------------------------------------------------------------------------
#--------------------------
#calculating more variables
#--------------------------
#1)LUE=GPP/fAPAR*ppfd
#unit-->GPP: umol m-2 s-1; ppdf-->umol m-2 s-1; fAPRA: unitless
#2)GRVI=(gcc-rcc)/c(gcc+rcc)
for(i in 1:length(df_len5_nonnorm)){
#
df_proc<-df_len5_nonnorm[[i]]
df_proc$LUE<-df_proc$gpp_obs/c(df_proc$fapar_itpl*df_proc$ppfd_fluxnet2015)
df_proc$GRVI<-c(df_proc$gcc_90-df_proc$rcc_90)/c(df_proc$gcc_90+df_proc$rcc_90)
#assign value back:
df_len5_nonnorm[[i]]<-df_proc
}
#-------------------------------------------------------------------------
#(4)going to compare the "event" and "non-event" site
#-------------------------------------------------------------------------
#-------------------------------------------------------------------------
#start plotting
#-------------------------------------------------------------------------
library(plyr)
library(ggplot2)
library(cowplot)
library(grid)
#function used to compare the "event" and "non_event" sites using geom_ribbon
#source the comparsion test written by me:
fun.path<-"D:/Github/photocold/R/Step2_identify_events/Functions/functions_from_YP/"
source(paste0(fun.path,"Difference_test_for_2Classes.R"))
df<-df_len5_nonnorm
comp_var<-"temp_min_fluxnet2015"
var_unit<-"()"
do_norm<-FALSE
do_legend<-FALSE
#
df.event<-df$df_dday
df.noevent<-df$df_noevent_dday
#------------------------------------
#remove the sites that have the point numbers smaller than 10
#------------------------------------
N_value<-ddply(df.noevent,.(sitename),summarise,N=length(date))
rm_sites<-subset(N_value,N<10)
if(nrow(rm_sites)>=1){
for(i in nrow(rm_sites)){
rm_site_name<-rm_sites[i]
df.noevent<-df.noevent[df.noevent$sitename!=as.character(rm_site_name),]
}
}
df.noevent<-df.noevent
#--------------------------------
#selected the most relevant vars
#for the comparison,select the original variable if "do_norm"==FALSE,otherwise "do_norm"==TRUE
#--------------------------------
if(do_norm==FALSE){
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
}
df<-df_len5_nonnorm
comp_var<-"temp_day_fluxnet2015"
var_unit<-"()"
do_norm<-FALSE
do_legend<-FALSE
#
df.event<-df$df_dday
df.noevent<-df$df_noevent_dday
#------------------------------------
#remove the sites that have the point numbers smaller than 10
#------------------------------------
N_value<-ddply(df.noevent,.(sitename),summarise,N=length(date))
rm_sites<-subset(N_value,N<10)
if(nrow(rm_sites)>=1){
for(i in nrow(rm_sites)){
rm_site_name<-rm_sites[i]
df.noevent<-df.noevent[df.noevent$sitename!=as.character(rm_site_name),]
}
}
df.noevent<-df.noevent
#--------------------------------
#selected the most relevant vars
#for the comparison,select the original variable if "do_norm"==FALSE,otherwise "do_norm"==TRUE
#--------------------------------
if(do_norm==FALSE){
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
}
if(do_norm==TRUE){
comp_var_norm<-paste0("ds",comp_var)
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
#
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
#also make var_unit()==""
var_unit<-c()
}
#--------------------------------------
#plotting
#--------------------------------------
# Create a text
grob_event <- grobTree(textGrob("Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="red", fontsize=18, fontface="italic")))
# grob_event_name <- grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                      gp=gpar(col="red", fontsize=18, fontface="italic")))
grob_nonevent <- grobTree(textGrob("Non-Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="red", fontsize=18, fontface="italic")))
# grob_nonevent_name<-grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                       gp=gpar(col="red", fontsize=18, fontface="italic")))
#y axis range:
ymin<-min(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
ymax<-max(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
#x axis range
# x_range_event<-range(df.event_sel$doy)
# x_range_nonevent<-range(df.nonevent_sel$doy)
###start to make the quantiile plot:
df.event_sel$flag<-rep("GPP overestimated sites",nrow(df.event_sel))
df.nonevent_sel$flag<-rep("GPP non-overestimated sites",nrow(df.nonevent_sel))
df.event_sel
#
df.event_sel<-df.event_sel[df.event_sel$dday<=sel_dday_event,]
df.nonevent_sel<-df.nonevent_sel[df.nonevent_sel$dday<=sel_dday_nonevent,]
##merge and classify
df.all<-rbind(df.event_sel,df.nonevent_sel)
df.all$flag<-factor(df.all$flag,levels = c("GPP overestimated sites","GPP non-overestimated sites"))
df.all
